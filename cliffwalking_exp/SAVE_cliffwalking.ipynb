{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:31<00:00, 631.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-3.2946097756811317, 0.7016945263508425)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility import *\n",
    "import operator\n",
    "from itertools import product\n",
    "from itertools import accumulate\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.interpolate import BSpline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from numpy.linalg import inv\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import integrate\n",
    "\n",
    "from model.AGENT import *\n",
    "\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sys\n",
    "# if \"../\" not in sys.path:\n",
    "#   sys.path.append(\"../\") \n",
    "from collections import defaultdict\n",
    "from lib.envs.cliff_walking import CliffWalkingEnv\n",
    "from lib.envs.windy_gridworld import WindyGridworldEnv\n",
    "\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "from scipy.optimize import Bounds\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = CliffWalkingEnv()\n",
    "Q_space = np.load(\"Q-table-cliff.npz\")[\"xxx\"]\n",
    "Q_space2 = np.load(\"Q-table-cliff.npz\")[\"xxx\"]\n",
    "\n",
    "prob1 = [1.0 for i in range((env.nA))]\n",
    "prob1 = prob1/np.sum(prob1)\n",
    "\n",
    "###################\n",
    "## discount rate ##\n",
    "###################\n",
    "gamma = 0.7\n",
    "###################################\n",
    "## parameter for behavior policy ## larger --> more expert \n",
    "###################################\n",
    "betabeta = 0.5\n",
    "#################################\n",
    "## parameter for target policy ##\n",
    "#################################\n",
    "alpha = 1\n",
    "#################################\n",
    "## parameter for MC repetition ##\n",
    "#################################\n",
    "n_MC = 20000\n",
    "sample_size = 1000\n",
    "\n",
    "def sample_policy(observation, alpha = alpha):\n",
    "    prob2 = alpha*Q_space[observation,:] +(1-alpha)*prob1\n",
    "    return np.random.choice(env.nA,1,p=prob2)[0] ## 4个action 选一\n",
    "        \n",
    "def behavior_policy(observation,beta=betabeta):\n",
    "    prob2 = beta*Q_space[observation,:]+ (1-beta)*prob1 \n",
    "    return np.random.choice(env.nA,1,p=prob2)[0]\n",
    "\n",
    "a = simulation(env, n = sample_size, reward_dicount = gamma, scale = \"Cliffwalk\")\n",
    "\n",
    "output, _, _ = a.evaluate_policy(policy = sample_policy, seed = None, S_init = None, n = n_MC) \n",
    "est_mean = np.mean(output)\n",
    "est_mean, np.std(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check infer\n",
    "sample_size = 500\n",
    "\n",
    "env = CliffWalkingEnv()\n",
    "\n",
    "\n",
    "Q_space = np.load(\"Q-table-cliff.npz\")[\"xxx\"]\n",
    "Q_space2 = np.load(\"Q-table-cliff.npz\")[\"xxx\"]\n",
    "\n",
    "prob1 = [1.0 for i in range((env.nA))]\n",
    "prob1 = prob1/np.sum(prob1)\n",
    "\n",
    "\n",
    "betabeta = 0.5\n",
    "alpha = 1\n",
    "def sample_policy(observation,alpha= alpha):\n",
    "    prob2 = alpha*Q_space[observation,:] +(1-alpha)*prob1\n",
    "    return np.random.choice(env.nA,1,p=prob2)[0] ## 4个action 选一\n",
    "        \n",
    "def behavior_policy(observation,beta=betabeta):\n",
    "    prob2 = beta*Q_space[observation,:]+ (1-beta)*prob1 ## behavior这么聪明？\n",
    "    return np.random.choice(env.nA,1,p=prob2)[0]\n",
    "\n",
    "a = simulation(env, n = sample_size, reward_dicount = gamma, scale = \"Cliffwalk_noise\")\n",
    "\n",
    "\n",
    "rep = 100\n",
    "filename_CI = 'CI_store_cliff_walk_fixed'\n",
    "outfile_CI = open(filename_CI, 'ab')\n",
    "est_mean = est_mean\n",
    "count = 0\n",
    "AL = []\n",
    "pred_all_basis = []\n",
    "for i in range(rep):\n",
    "    try:\n",
    "        a.buffer = {} ## when using gen_buffer, we should empty the buffer first!!\n",
    "        a.gen_buffer(total_N = None, S_init = None, policy = behavior_policy )\n",
    "        a.B_spline_degrade()\n",
    "        lower_bound, upper_bound = a.inference(policy = sample_policy, S = 36)\n",
    "        print(\"obtain bounds:\", lower_bound, upper_bound, \"estimated value\", (lower_bound + upper_bound)/2 )\n",
    "        pickle.dump([lower_bound,upper_bound], outfile_CI)\n",
    "        AL.append(upper_bound - lower_bound)\n",
    "        if lower_bound < est_mean and est_mean < upper_bound:\n",
    "            count += 1\n",
    "        pred_all_basis.append((lower_bound + upper_bound) / 2)\n",
    "        #if i % 10 == 0 :\n",
    "        #    print(\"iteration,\", i , count, \n",
    "        #      \"CI\", lower_bound, upper_bound, \"sigma_2\", a.sigma2, \n",
    "        #      \"estimated mean\", np.mean([lower_bound[0], upper_bound[0]]))\n",
    "\n",
    "        print(count / len(AL), np.mean(AL), np.mean(pred_all_basis) )\n",
    "    except:\n",
    "        print(\"+\" * 10 +\" 1 \" + \"+\" * 10)\n",
    "outfile_CI.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sample size 500 gamma 0.7\n",
      "ourmethod: CI 0.967, AL 0.143, pred -3.299, MSE 0.00113(0.00140)\n"
     ]
    }
   ],
   "source": [
    "print(\"for sample size\", sample_size, \"gamma\" , gamma )\n",
    "def mse(aaa, true = -3.301610434961245):\n",
    "    aaa = np.array(aaa)\n",
    "    aaa = aaa[aaa>-100]\n",
    "    return [np.mean((((aaa-true)*(aaa-true)))),np.sqrt(np.var((aaa-true)*(aaa-true)))]\n",
    "print(\"ourmethod: CI %.3f, AL %.3f, pred %.3f, MSE %.5f(%.5f)\" %(count / len(AL),  np.mean(AL), np.mean(pred_all_basis), *mse(pred_all_basis, est_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
